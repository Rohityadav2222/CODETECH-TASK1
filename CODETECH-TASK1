import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import confusion_matrix , classification_report ,accuracy_score,ConfusionMatrixDisplay
print("modul loaded")
## **Read Data**
name_column=['id','entity','target','Tweet content']
df=pd.read_csv('/kaggle/input/twitter-entity-sentiment-analysis/twitter_training.csv',names=name_column)
df
df.isna().sum()
## **Explore & cleaning**
df=df.drop(columns=['id','entity'],axis=1)
df
df.isna().sum()
count=df['target'].value_counts()
count
plt.figure(figsize=(12,8))
sns.barplot(x=count.index,y=count.values,palette='viridis')
plt.title('target_counts')
plt.xlabel('target')
plt.ylabel('count')
plt.show()
## **preprocessing**
ps=PorterStemmer()
stops=set(stopwords.words('english'))
def preprocessing_text(text):
    text = re.sub(r'[^a-zA-Z\s]', '',text)
    text=text.lower()
    token=text.split()
    token=[ps.stem(word) for word in token if word not in stops]
    return ' '.join(token)
df['Tweet content']=df['Tweet content'].apply(preprocessing_text)
df['Tweet content']
0                                 im get borderland murder
1                                         come border kill
2                                   im get borderland kill
3                                im come borderland murder
4                                 im get borderland murder
                               ...                        
74677    realiz window partit mac like year behind nvid...
74678    realiz mac window partit year behind nvidia dr...
74679    realiz window partit mac year behind nvidia dr...
74680    realiz window partit mac like year behind nvid...
74681    like window partit mac like year behind driver...
Name: Tweet content, Length: 73996, dtype: object
## feature Extraction
tf=TfidfVectorizer(max_features=5000)
x=tf.fit_transform(df['Tweet content'])
y=df['target']
x.shape
y.shape
## **split data**
X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.2,shuffle=True,random_state=42)
## **Build models**
models = {
    'Naive Bayes': MultinomialNB(),
    'Decision tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    
}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print(f"\n--- {name} ---\n")
    print("Accuracy:", accuracy_score(y_test, y_pred))
    print("\nClassification Report:\n", classification_report(y_test, y_pred))
    print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
    ConfusionMatrixDisplay.from_predictions(y_test, y_pred)
